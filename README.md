# Visual Question Answering by Optical Character Recognition

The model receives images and extracts the text considering the distancing aspects of each content. Lastly, the LLM pipleine is created to receive a prompt template as well as question of the user. The default model is created on LLAMA2 model quantized by Bloke. To use the LLM storage space of almost 8G as well as GPU is required.   

The GPT4 based version of model also is available on VQA_OCR_GPT branch. 
